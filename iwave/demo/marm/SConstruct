########################################################################
####################### TRIP DEMO SCONSTRUCT ###########################
########################################################################

###### JOB DICTIONARY: PYTHON DICTIONARY OF JOB NAME AND CORRESPONDING 
###### COMMAND, DEPENDENCY, AND OTHER NECESSARY EXECUTION INFO
######
###### FORM:
######   jobs = {
######     <job name> : [<command string>, (other stuff - see below)],
######     ...
######   }
######
###### ASSUMPTIONS:
###### - JOB NAME IS ALSO ROOT NAME OF PAR FILE IN THIS DIRECTORY
######   example: job name = 'data', then par file name = './data.par'
######   (exception: tmpdata task, see below)
###### - JOB NAME WILL BE USED AS NAME OF BUILD SUBDIRECTORY FOR JOB
######   example: job name = 'data', then script builds subdir ./data
######   and executes job in this directory
###### - EACH JOB EXECUTES EXACTLY ONE COMMAND
###### - COMMANDS ARE ASSUMED TO BE BUILT - BUILD COMMANDS FIRST!
###### - COMMAND NAME IS COMPLETE, WITH ALL NECESSARY SCRIPTS, FLAGS, 
######   AND OPTIONS
######   example: to use mpirun on 8 processors to execute cmd.x which
######   resides in PATH_TO_COMMANDS (environment), the command string 
######   should read 
######   'mpirun -np 8 $PATH_TO_COMMANDS/cmd.x'
###### - JOB BUILD COMMAND: 'jobs[jobname] par=jobname.par'
######   example: if jobs dictionary includes this line:
######   'data' : 'mpirun -np 256 $IWAVE/esg/main/esg.x'
######   then the command to build this job is
######   'mpirun -np 256 $IWAVE/esg/main/esg.x par=data.par'
######   and this string is fed to a shell (interactive) or embedded in
######   script which is then submitted (batch)
###### - SCONS CLEAN COMMAND SHOULD REMOVE ALL JOB DIRECTORIES CREATED
######   BY THIS SCRIPT (IT WILL!), AND THESE CONTAIN ALL OUTPUT OF THE
######   CORRESPONDING COMMANDS. CONSEQUENCE: NO FILE CAN BE BOTH INPUT
######   AND OUTPUT FOR THE SAME TARGET.
######   example: a SEGY file cannot be both the source of header info 
######   and the output data file - so a feature of early IWAVE commands
######   cannot be exercised in these demos
###### - Intermediate data is by convention stored in $DATAPATH/iwave, which
######   is created by target tmpdata. Therefore this target should be always
######   be included in the scripts dictionary, unless no intermediate data at all 
######   is involved in any task (unlikely!!!)

###### Structure of the job dictionary:
###### key    = name of job = name of output directory
###### val[0] = command prefix, eg. 'mpirun -np ...'
###### val[1] = path to command (may be empty only if a special branch of make takes care of this target)
###### val[2] = dependency list (may be empty)
###### val[3] = batch key ('' for interactive, else 'pbs' or 'sge' or ...)
###### val[4] = wallclock limit (batch only)
###### val[5] = resource alloc (batch only)
###### val[6] = queue (batch only)

################### ENVIRONMENT-DEPENDENT USER INPUT ###################

########################################################################
################### FLAG: MADAGASCAR OR STANDALONE #####################
########################################################################

MADAGASCAR = True

# madagascar version
#if MADAGASCAR:
#    ROOT = os.path.abspath(os.path.expandvars('$RSFROOT/bin')) + '/'    
#    standardmodel = ROOT + 'sfstandardmodel'
#    asg           = ROOT + 'sfasg'
# autonomous version
#else:
ROOT = '../../../'
standardmodel = ROOT + 'demo/main/standardmodel.x'
asg           = ROOT + 'asg/main/asg.x'

########################################################################
######################### JOB DEFINITION TABLE #########################
########################################################################

### jobs driven by parameter tables:
jobs = {
#'marm4m' : ['',asg, ['sudata', 'dn3d_40m', 'vp3d_40m'],'','','',''],
'line100m' : ['',asg, ['marmousi'],'','','',''],
'line100m8k' : ['',asg, ['marmousi'],'','','',''],
}

### scripts:
scripts = {
#'sudata'  : ['tmpdata', 'sudata.sc'],
'tmpdata' : [],
'marmousi'     : ['tmpdata']
}

### remote data fetches:
fetches = {
'line_fix.su' : ['marmousi', 'http://www.trip.caam.rice.edu'],
'velocity.HH' : ['marmousi', 'http://www.trip.caam.rice.edu'],
'density.HH'  : ['marmousi', 'http://www.trip.caam.rice.edu'],
}

########################################################################
################# OPTIONS COMMON FOR ALL BATCH JOBS ####################
########################################################################

###### EMAIL ADDRESS FOR BATCH SYSTEM NOTIFICATION
MAIL = 'symes@caam.rice.edu'

###### ACCOUNT NAME
ACCT = 'FDTD3D-Cont'

########################################################################
# generally the right choice for temp data - can be modified ###########
########################################################################
import os
DATAPATH = os.getenv('DATAPATH','.')
if DATAPATH[len(DATAPATH)-1] == '/':
    TMPDATAPATH = DATAPATH + 'iwave'
else:
    TMPDATAPATH = DATAPATH + '/iwave'

########################################################################
###### interface to sconscript files - do not edit below this line #####
########################################################################

# register jobs, scripts, and fetch targets as targets
for tgt in jobs.keys():
    Default(tgt)

for tgt in scripts.keys():
    Default(tgt)

for file in fetches.keys():
    tgt = TMPDATAPATH + '/' + file
    Default(tgt)

# all fetches must be done here, to satisfy implicit dependencies
# all other tasks are assumed to be dependencies of the fetches
if len(fetches.keys()) > 0 :
    from rsf.proj import *
    for file in fetches.keys():
        tgt = TMPDATAPATH + '/' + file
        Fetch(tgt,fetches[file][0],server=fetches[file][1])   
	for job in jobs.keys():
	    Depends(job,tgt)
        for script in scripts.keys():
            Depends(script,tgt)

Export('MADAGASCAR TMPDATAPATH ROOT jobs scripts fetches')
SConscript('./SConscript')

