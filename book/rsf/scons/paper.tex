\title{Reproducible research in computational geophysics \\ using SCons}

\lefthead{Fomel \& Hennenfent}
\righthead{Reproductible research}

\author{Sergey Fomel and Gilles Hennenfent}
\email{sergey.fomel@beg.utexas.edu, ghennenfent@eos.ubc.ca}

\maketitle

\begin{abstract}
SCons (from Software Construction) is
\end{abstract}

\section{Introduction}

\subsection{Reproducible research philosophy}

Peer review is the backbone of scientific progress. From the ancient
alchemists, who worked in secret on magic solutions to insolvable
problems, the modern science has come a long way to become a social
enterprise, where hypotheses, theories, and experimental results are
openly published and verified by the community. By reproducing and
verifying previously published research, a researcher can take new
steps to advance the progress of science.

Traditionally, scientific disciplines are divided into theoretical and
experimental studies. Reproduction and verification of theoretical
results usually requires only imagination (apart from pencils and
paper), experimental results are verified in laboratories using
equipment and materials similar to those described in the publication.

During the last century, computational studies emerged as a new
scientific discipline. Computational experiments are carried out on a
computer by applying numerical algorithms to digital data. How
reproducible are such experiments? On one hand, reproducing the result
of a numerical experiment is a difficult undertaking. The reader needs
to have access to precisely the same kind of input data, software and
hardware as the author of the publication to reproduce the result. It
is often difficult or impossible to provide detailed specifications
for these components. On the other hand, basic components of a
computational system such as operating systems and file formats are
getting increasingly standardized, and new components can be shared in
principle because they simply represent digital information
transferable over the Internet.

The practice of software sharing has fueled the miraculously efficient
development of Linux, Apache, and many other open-source software
projects.  Its proponents often refer to this ideology as an analog of
the scientific peer review tradition. Eric Raymond, one of the
best-known supporters of the open-source movement, writes
\cite[]{taoup}:
\begin{quote}
  Abandoning the habit of secrecy in favor of process transparency and
  peer review was the crucial step by which alchemy became chemistry.
  In the same way, it is beginning to appear that open-source
  development may signal the long-awaited maturation of software
  development as a discipline.
\end{quote}
While software development is trying to imitate science, computational
science needs to borrow from the open-source model in order to sustain
itself as a fully scientific discipline.

In computer science, the concept of publishing and explaining computer
programs goes back to the idea of \emph{literate programming} promoted
by \cite{knuth} and expended by many other researchers
\cite[]{thimbleby}. In his 2004 lecture on ``better programming'',
Harold Thimbleby says\footnote{url:http://www.uclic.ucl.ac.uk/harold/}
\begin{quote}
  We want ideas, and in particular programs, that work in one place to
  work elsewhere. One form of objectivity is that published science
  must work elsewhere than just in the author's laboratory or even
  just in the author's imagination; this requirement is called
  \emph{reproducibility}.
\end{quote}

The quest for peer review and reproducibility is especially important
for computational geosciences and computational geophysics in
particular. The very first paper published in \emph{Geophysics} was
titled ``Black magic in geophysical prospecting''
\cite[]{GEO01-01-00010008,TLE02-03-00280031} and presented an account
of different ``magical'' methods of oil explorations promoted by
entrepreneurs in the early days of geophysical exploration industry.
Although none of these methods exist today, it is not a secret that
industrial practice is full of nearly magical tricks, often hidden
besides a scientific appearance. Only a scrutiny of peer review and
result verification can help us distinguish magic from science and
advance the latter.

Nearly ten years ago, the technology of reproducible research in
geophysics was pioneered by Jon Claerbout and his students at the
Stanford Exploration Project (SEP).  SEP's system of reproducible
research requires the author of a publication to document creation of
numerical results from the input data and software sources to let
others test and verify the result reproducibility
\cite[]{SEG-1992-0601,matt}.
%% In Claerbout's words
%% \footnote{http://sepwww.stanford.edu/research/redoc/IRIS.html},
%% \begin{quote}
%%   The purpose of reproducible research is to facilitate someone going a step
%%   further by changing something. The first step that someone will want to make
%%   is to be sure that your work is reproducible before they change and improve
%%   upon it. 
%% \end{quote}
%% \begin{quote}
%%   It takes some effort to organize your research to be reproducible.
%%   We found that although the effort seems to be directed to helping other
%%   people stand up on your shoulders, the principal beneficiary is generally
%%   the author herself. This is because time turns each one of us into another
%%   person, and by making effort to communicate with strangers, we help
%%   ourselves to communicate with our future selves.
%% \end{quote}
The discipline of reproducible research was also adopted and
popularized in the statistics and wavelet theory community by
\cite{donoho}. It is referenced in the popular wavelet theory books
\cite[]{hubbard,mallat}.  However, the adoption or reproducible
research practice by computational geoscientists outside of SEP has
been slow.  Partially, this is caused by difficult and inadequate
tools.

%What kind of documentation is required to make geophysical numerical
%experiments reproducible? Geophysical data analysis involves remote datasets
%that are typically passed through several data processing steps before a final
%image is created and some information about the subsurface geology is
%inferred.  Keeping a precise record of the processing history is necessary for
%reproducing and verifying the result. 

%The closest analog from other
%disciplines is medicine. Both geosciences and medical sciences study unique
%objects (the Earth planet and the human organism respectively). Each
%geophysical dataset is in some sense as unique as each medical patient, and
%keeping a careful log of the data analysis history is essential for scientific
%validation of the methods applied to it.

\subsection{Tools for reproducible research}

The reproducible research system developed at Stanford is based on
``make''\footnote{Originally, SEP used ``cake'', a dialect of ``make''
  \cite[]{Nichols.sep.61.341,Claerbout.sep.67.145,Claerbout.sep.73.451,Claerbout.sep.77.427}.
  The system was converted to ``GNU make'', a more standard dialect,
  by \cite{Schwab.sep.89.217}.}, a Unix software construction utility.
The ``make'' program keeps track of dependencies between different
components of the system and the software construction targets, which,
in the case of a reproducible research system, turn into figures and
manuscripts. The targets and commands for their construction are
specified by the author in ``makefiles'', which serve as databases for
defining source and target dependencies. A dependency-based system
leads to rapid development, because when one of the sources changes,
only parts that depend on this source get recomputed.  \cite{donoho}
based their system on Matlab, a popular integrated development
environment \cite[]{matlab}, produced by MathWorks.  While Matlab is
an adequate tool for prototyping numerical algorithms, it may not be
sufficient for large-scale computation, typical for many applications
in computational geophysics.

``Make'' is an extremely useful utility employed by thousands of
software development projects \cite[]{make}. Unfortunately, it is not
well designed from the user experience prospective. ``Make'' employs
an obscure and limited special language (a mixture of Unix shell
commands and special-purpose commands), which often appears confusing
to unexperienced users. According to Peter van der Linden, a software
expert from Sun Microsystems \cite[]{linden},
\begin{quote}
  ``Sendmail'' and ``make'' are two well known programs that are
  pretty widely regarded as originally being debugged into existence.
  That's why their command languages are so poorly thought out and
  difficult to learn. It's not just you -- everyone finds them
  troublesome.
\end{quote}
The inconvenience of ``make'' command language is also in its limited
capabilities.  The reproducible research system includes not only
custom ``make'' rules but also an obscure and hardly portable
agglomeration of shell and Perl scripts that extend ``make''.

Several alternative systems for dependency-checking software
construction have been developed in recent years. One of the most
promising new tools is SCons, enthusiastically endorsed by
\cite{dubois}. The SCons initial design won the Software Carpentry
competition sponsored by Los Alamos National Laboratory in 2000 in the
category of ``a dependency management tool to replace make''.  Some of
the main advantages of SCons are:
\begin{itemize}
\item SCons configuration files are Python scripts. Python is a modern
  programming language praised for its readability, elegance,
  simplicity, and power \cite[]{python1,python2}.
  \cite{TLE21-03-02600267} recommend Python as the first programming
  language for geophysics students.
\item SCons offers reliable, automatic, and extensible dependency
  analysis -- no more ``make depend'' or ``make clean'' to get all of
  the dependencies.
\item SCons has built-in support for many programming languages and
  systems: C, C++, Fortran, Java, LaTeX, CVS, and others.
\item While ``make'' relies on timestamps for detecting file changes
  (creating numerous problems on platforms with different system
  clocks), SCons uses by default a much more reliable detection
  mechanism employing MD5 signatures. It can detect changes not only
  in files but also in commands used to build them.
\item SCons provides integrated support for parallel builds.
\item SCons provides configuration support analogous to the ``autoconf''
  utility for testing the environment on different platforms.
\item SCons creates a global view of all dependencies -- no more
  multiple build passes or touching and reordering targets in order to
  build everything.
\item SCons is designed from the ground up as a cross-platform tool.
  It is known to work equally well on both POSIX systems (Linux, Mac
  OS X, Solaris, etc.) and Windows.
\item The stability of SCons is assured by an incremental development
  methodology utilizing comprehensive regression tests\footnote{As of
    time of this writing, SCons is in a beta version 0.96 approaching
    the 1.0 official release. See \url{http://www.scons.org/}.}.
\item SCons is publicly released under a liberal open-source license.
\end{itemize}

In this paper, we propose to adopt SCons as a new platform for
reproducible research in scientific computing.

\subsection{Paper organization}

%This paper is organized ``by example''. We will take a small project
%typical for geophysical data processing and show how it can be
%organized with SCons.  The example is taken from the collection of
%demos in Seismic Unix \cite[]{su}.  Next, we reproduce a similar
%example using the newly developed RSF (regularly sampled file)
%software package. Finally, we show how to adopt SCons for generating
%documents such as the one you are reading now.

\newpage
\section{Setting up projects}
\subsection{Getting started with RSF}

In this example, we will download an image from an anonymous data
server, perform basic manipulations, and display the result.

\definecolor{frame}{rgb}{0.905,0.905,0.905}
\lstset{language=Python,backgroundcolor=\color{frame},showstringspaces=false,numbers=left,numberstyle=\tiny}

Open a file named ``SConstruct'' in your favorite editor and start it
with the line
%
\lstinputlisting[firstline=1,lastline=1,frame=single]{easystart/SConstruct}
%
This loads the RSF project management module \texttt{rsfproj}, which
provides our extention to SCons.
%
Add a Fetch command as follows
\lstinputlisting[firstline=3,lastline=3,frame=single]{easystart/SConstruct}
which instructs SCons to connect to an anonymous data server (default
is BEG FTP server) and extract (fetch) the data file ``lena.img'' from
the ``data/imgs'' directory. By running \texttt{scons lena.img}
%
the file ``lena.img'' is downloaded to your current folder. The
equivalent command lines are \footnote{use login: anonymous, password:
  anonymous}
\begin{verbatim}
bash$ ftp egl.beg.utexas.edu
ftp> bin
ftp> cd data/imgs
ftp> get lena.img
ftp> bye
\end{verbatim}
%
Add now the following Flow command
%
\lstinputlisting[firstline=5,lastline=9,frame=single]{easystart/SConstruct}
%
to prepare the RSF header file. A Flow is a rule to generate target(s)
from source(s) using command(s). In this specific case, the Flow has
one source ``lena.img'' and one target ``ulena.rsf'' (the default
extension for sources and targets is .rsf) The target is obtained from
the source by running
%
\begin{verbatim}
bash$ echo n1=512 n2=513 d1=1 d2=1 in=lena.img \
data_format=native_uchar > ulena.rsf
\end{verbatim}
%
Since echo does not take a standard input, stdin is set to 0 in the
Flow command otherwise the first source is the standard input.
Likewise, the first target is the standard output unless otherwise
specified. Note the triple quotes used because the actual command is
broken into several lines in the SConstruct. Note also that
``lena.img'' is refered as ``\$SOURCE'' in the command. Run
\texttt{scons ulena.rsf} to execute the Flow command and obtain the
ASCII header file ``ulena.rsf''.  The next step is to convert the
binary data ``lena.img'' into a RSF file.  To do so add
%
\lstinputlisting[firstline=10,lastline=10,frame=single]{easystart/SConstruct}
%
The equivalent command line is
%
\begin{verbatim}
bash$ < ulena.rsf sfdd type=float > flena.rsf
\end{verbatim}
%
Run \texttt{scons flena.rsf}. At this point the Lena image is
converted to RSF file format with a header file ``flena.rsf'' in the
current directory and a binary file ``flena.rsf@'' in the data
directory (environment variable DATAPATH). The last two steps before
displaying Lena (we know you are impatient...)  is windowing the image
and subtracting its mean. Add the following Flow command
%
\lstinputlisting[firstline=11,lastline=11,frame=single]{easystart/SConstruct}
%
to remove the first sample along the second axis. Run \texttt{scons
  flena512.rsf}. Finally
%
\lstinputlisting[firstline=12,lastline=13,frame=single]{easystart/SConstruct}
%
to substract the mean. Note the keyword ``input'' in the output
formula which refers to the standard input of the ``sfmath'' function.
Run \texttt{scons zmflena512.rsf}. It is now time to display Lena...
Add the Result command
%
\lstinputlisting[firstline=15,lastline=19,frame=single]{easystart/SConstruct}
%
which command line equivalent is
\begin{verbatim}
bash$ < zmflena512.rsf sfgrey title="Lena" transp=n minval=-150 \
maxval=150 clip=120 screenratio=1 titlesz=14 | tube
\end{verbatim}
%
Running \texttt{scons lena.view} displays the Lena image. It also
create a ``Fig'' directory in the current folder where it stores the
result ``lena.vpl''. End the SConstruct with
%
\lstinputlisting[firstline=21,lastline=21,frame=single]{easystart/SConstruct}

\subsection{Combining RSF and Python in SConstruct}

\lstinputlisting[firstline=1,lastline=83,frame=single]{rsfpy/SConstruct}

\subsection{LaTeX example}

\section{Command summary}

The following is a summary of SConstruct commands and default SCons
targets that are set in our reproducible research environment.

\begin{description}
\item[\texttt{Flow(target,source,command)}] \dotfill \pageref{flow} \\
  A rule to generate \texttt{target} from \texttt{source} using
  \texttt{command}.
\end{description}

\section{Open source availability}

SU software package is available from... RSF is available from... The
RSF distribution also contains \texttt{suproj} and \texttt{rsfproj}
modules used in the examples of this paper.

\bibliographystyle{seg}
\bibliography{SEG,SEP2,scons}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
