\published{Computers \& Geosciences, (2014), \url{http://dx.doi.org/10.1016/j.cageo.2014.04.004}}

\title{RTM using effective boundary saving: A staggered grid GPU implementation}

\renewcommand{\thefootnote}{\fnsymbol{footnote}}


\author{Pengliang Yang\footnotemark[1], Jinghuai Gao\footnotemark[1], and Baoli Wang\footnotemark[2] \\
\footnotemark[1]Xi'an Jiaotong University, National Engineering Laboratory for Offshore Oil Exploration, Xi'an, China, 710049\\
\footnotemark[2]CCTEG  Xi’an Research Institute, Xi’an, China, 710077
}


\righthead{Boundary saving in GPU-based RTM}
\lefthead{Yang et al.}

\footer{TCCS-7}

\maketitle

\begin{abstract}
 As an advanced imaging technology, reverse time migration (RTM) is a computational intensive process, which requires large memory to save the forward modeling wavefield in order to apply the imaging condition in the backward propagation steps. GPU has become one of the most widely used programming tools to accelerate the RTM computation. One key issue of GPU-based RTM is that the computation is much faster while the data exchange between host and device always takes longer time.  Many geophysicists choose to reconstruct the modeled wavefield instead of storing them on the disk, just saving the boundaries. In this paper, we propose effective boundary saving strategy in GPU-based RTM imaging, for regular grid finite difference and staggered grid finite difference. Even so, the memory requirement of effective boundary saving on GPU is still large for the limited GPU resource. To mitigate this conflict, the zero-copy pinned memory on CPU is also recommended to be utilized. We demonstrate the proposed approach with numerical examples.
\end{abstract}


\section{Introduction}


One-way equation based imaging techniques are inadequate to obtain obtain accurate images in complex media due to propagation direction changes in the background model \citep{biondi20063d}. These approaches are extremely limited when handling the problems of turning waves and  multi-pathing  in the model containing sharp wave-speed contrasts and steeply dipping reflectors. As an advanced imaging technology without dip and extreme lateral velocity limitation, reverse time migration (RTM) was proposed early  \citep{baysal1983reverse,m1983migration}, but not practical in terms of stringent computation and memory requirement.
However, it gained increasingly attention in recent years due to the tremendous advances in computer capability. Until recently, 3D prestack RTM is now feasible to obtain high fidelity images \citep{yoon20033d,guitton2006least}.

Nowadays, graphics processing unit (GPU) is a booming technology, widely used to mitigate the computational drawbacks in seismic imaging and inversion, from one-way depth migration \citep{liu2012gpu,lin2012application} to two-way  RTM \citep{hussain2011implementation,micikevicius20093d,clapp2010selecting}, from 2D to 3D  \citep{micikevicius20093d,abdelkhalek2009fast,foltinek2009industrial,liu20133d,michea2010accelerating}, from acoustic media to elastic \citep{weiss2013solving} and tilted transversely isotropic (TTI) media  \citep{guo2013application,suh2011expanding}, from isotropic to anisotropy \citep{liu2009anisotropic}. The investigators have tried many approaches:  such as the  Fourier integral method \citep{liu2012fourier},  spectral element method \citep{komatitsch2010running}, finite element method \citep{komatitsch2010high} as well as the rapid expansion method (REM) with pseudo-spectral approach \citep{kim2012acceleration}. A variety of applications are conducted, for instance, GPU-based RTM denoising \citep{ying2013denoise}, iterative velocity model building \citep{ji2012iterative}, multi-source RTM \citep{boonyasiriwat2010multisource}, as well as least-square RTM \citep{leader2012least}. Besides these advances, it also marched forward in  MPI-combined multi-GPU application and cluster programming \citep{komatitsch2010high,suh2010cluster}, as well as further hardware optimization using FPGA  \citep{fu2011eliminating,medeiros2011fpga}.


The superior speedup performance of the GPU-based imaging and inversion has been demonstrated by numerous studies. One key problem of GPU-based RTM is that the computation is much faster while the data exchange between host and device always takes longer time.   Many researchers choose to reconstruct the modeled wavefield instead of storing the modeling time history on the disk, just saving the boundaries. Even so, saving all the boundary on GPU is still not practical due to the limited memory resource. Thus, it is still necessary to further reduce reduce the boundary saving load to avoid data saving from GPU to CPU, which will greatly degrade the efficiency of GPU-based RTM imaging. Unlike most GPU-based imaging and inversion studies, this paper is devoted to the practical technical issues instead of speedup performance. Our main contribution is to propose an effective boundary saving strategy for regular grid finite difference and staggered grid finite difference, utilizing the zero-copy pinned memory.


\section{Overview of RTM and its computation}

In the case of constant density, the acoustic wave equation is written as
\begin{equation}\label{eq:scalar_wav}
\frac{1}{v^2(\textbf{x})}\frac{\partial^2 p(\textbf{x},t;\textbf{x}_s)}{\partial t^2}=\nabla^2 p(\textbf{x},t;\textbf{x}_s)+f(t)\delta(\textbf{x}-\textbf{x}_s)
\end{equation}
where $p(\textbf{x},t;\textbf{x}_s)$ is the wavefield excited by the source at the position $\textbf{x}=\textbf{x}_s$,  $v(\textbf{x})$ stands for the velocity in the media, $\nabla^2=\nabla\cdot\nabla=\partial_{xx}+\partial_{zz}$, $f(t)$ denotes the source function. For the convenience, we eliminate the source term hereafter and use the notation $\partial_u=\frac{\partial}{\partial u}$ and $\partial_{uu}=\frac{\partial}{\partial u^2}$, $u=x,z$. The forward marching step can be specified after discretization as
\begin{equation}\label{eq:forward}
p^{k+1}=2p^{k}-p^{k-1}+v^2\Delta t^2 \nabla^2 p^{k}.
\end{equation}
Based on the wave equation, the principle of RTM imaging can be interpreted as the cross-correlation of two wavefields at the same time level, one computed by forward time recursion, the other computed by backward time stepping \citep{symes2007reverse}.
 Mathematically, the cross-correlation imaging condition can be expressed as
\begin{equation}
I(\textbf{x})=\sum_{s=1}^{ns}\int_{0}^{t_{\max}}\mathrm{d}t \sum_{g=1}^{ng} p_s(\textbf{x},t;\textbf{x}_s)p_g(\textbf{x},t;\textbf{x}_g),
\end{equation}
where $I(\textbf{x})$ is the migrated image at point ${\bf x}$; and $p_s(\cdot)$ and $p_g(\cdot)$ are the source wavefield and receiver (or geophone) wavefield. The normalized cross-correlation imaging condition is designed by adding  the illumination compensation,
\begin{equation}
I(\textbf{x})=\sum_{s=1}^{ns}\frac{\int_{0}^{t_{\max}}\mathrm{d}t\sum_{g=1}^{ng} p_s(\textbf{x},t;\textbf{x}_s)p_g(\textbf{x},t;\textbf{x}_g)}{\int_{0}^{t_{\max}}\mathrm{d}t p_s(\textbf{x},t;\textbf{x}_s)p_s(\textbf{x},t;\textbf{x}_s)}.
\end{equation}


There are some possible ways to apply imaging condtion in RTM. The simplest one may be just storing the forward modeled wavefields on the disk, and reading them for imaging condition in the backward propagation steps. This approach requires frequent disk I/O and has been replaced by wavefield reconstruction method. The so-called wavefield reconstruction method is a way to recover the wavefield via backward reconstructing or forward remodeling, using the saved wavefield snaps and boundaries. By saving the last two wavefield snaps and the boundaries, one can reconstruct the wavefield of every time step, in time-reversal order. The checkpointing technique becomes very useful to further reduce the storage \citep{symes2007reverse,dussaud2008computational}. Of course, it is also possible to avert the issue of boundary saving by applying the random boundary condition, which may bring some noise in the migrated image \citep{clapp2009reverse,clapp2010selecting,liu2013wavefield,liu20133d}.


\section{Effective boundary saving}

In this paper, we mainly focus on finding the part of boundaries which is really necessary to be saved (referred to as the effective boundary in this paper), even though there are many other practical implementation issues in GPU-based RTM \citep{liu2012issues}.  In what follows, we introduce the effective boundary saving for regular grid and staggered grid finite difference. All the analysis will be based on 2-D acoustic wave propagation in RTM. In other cases, the wave equation may change but the principle of effective boundary saving remains the same.

\subsection{Which part of the wavefield should be saved?}
\inputdir{.}

To reconstruct the modeled wavefiled in backward steps rather than read the stored source wavefield from the disk, one can reuse the same template by exchanging the role of $p^{k+1}$ and $p^{k-1}$, that is,
\begin{equation}\label{eq:forward2}
p^{k-1}=2p^{k}-p^{k+1}+v^2\Delta t^2 \nabla^2 p^{k}.
\end{equation}
We conduct the modeling (and the backward propagation in the same way due to template reuse):
\begin{displaymath}
\begin{split}
 &for\;ix,iz... \quad p_0(:)=2p_1(:)-p_0(:)+v^2(:)\Delta t^2 \nabla^2 p_1(:)\\
 &ptr=p_0;p_0=p_1;p_1=ptr;// \mathrm{exchange\; pointer}
\end{split}
\end{displaymath}
where $(:)=[ix,iz]$, $p_0$ and $p_1$ are $p^{k+1}$ and $p^{k-1}$, respectively. When the modeling is finished, only the last two wave snaps ($p^{nt}$ and $p^{nt-1}$) as well as the saved boundaries are required to do the backward time recursion.


As you see, RTM begs for an accurate reconstruction before applying the imaging condition using the backward propagated wavefiled. The velocity model is typically extended with sponge absorbing boundary condition (ABC) \citep{cerjan1985nonreflecting} or perfectly matched layer (PML) and its variants \citep{komatitsch2007unsplit} to a larger size. In  Figure 1, the original model size $A_1A_2A_3A_4$ is extended to $C_1C_2C_3C_4$. In between is the artificial boundary ($C_1C_2C_3C_4\backslash A_1A_2A_3A_4$).
Actually, the wavefield that we try to reconstruct is not the part in extended artificial boundary $C_1C_2C_3C_4\backslash A_1A_2A_3A_4$ but the part in the original model zone $A_1A_2A_3A_4$. We can reduce the boundary load further (from whole $C_1C_2C_3C_4\backslash A_1A_2A_3A_4$ to part of it $B_1B_2B_3B_4$ ) depending on the required grids in finite difference scheme, as long as we can maintain the correctness of wavefield in $A_1A_2A_3A_4$. We do not care about the correctness of the wavefield neither in $A_1A_2A_3A_4$ nor in the effective zone $B_1B_2B_3B_4$ (i.e. the wavefield in $C_1C_2C_3C_4\backslash B_1B_2B_3B_4$). Furthermore, we only need to compute the imaging condition in the zone $A_1A_2A_3A_4$, no concern with the  part in $C_1C_2C_3C_4\backslash A_1A_2A_3A_4$.

\plot{fig1}{width=0.6\textwidth}{Extend the model size with artificial boundary. $A_1A_2A_3A_4$ indicates the original model size ($nz\times nx$).  $C_1C_2C_3C_4$ is the extended model size $(nz+2nb)(nx+2nb)$. $B_1B_2B_3B_4\backslash A_1A_2A_3A_4$ is the effective boundary zone.}

\subsection{Effective boundary for regular grid finite difference}


Assume $2N$-th order finite difference scheme is applied. The laplacian operator is specified by
\begin{equation}
\begin{array}{rl}
 \nabla^2 p^{k}&=\partial_{xx}p^{k}+\partial_{zz}p^{k}\\
 &=\frac{1}{\Delta z^2}\sum_{i=-N}^Nc_ip^k[ix][iz+i]+\frac{1}{\Delta x^2}\sum_{i=-N}^Nc_i p^k[ix+i][iz]\\
\end{array}
\end{equation}
where $c_i$ is given by Table 1, see a detailed derivation in \cite{fornberg1988generation}. The laplacian operator has $x$ and $z$ with same finite difference structure. For $x$ dimension only, it has been shown in Figure 2. In 2-D case, the required boundary zone has been plotted in Figure 3a. Note that four corners in $B_1B_2B_3B_4$ in Figure 1 are not needed. This is exactly the boundary saving scheme proposed by \cite{dussaud2008computational}.

%\newpage
\begin{table*}
  \centering
  \caption{Finite difference coefficients for regular grid}\label{table:1}
  \begin{tabular}{l|c|c|c|c|c|c|c|c|c}
     \hline
     Order ($2N$)  &-4 	& -3 	& -2 	& -1 	& 0 	& 1 	& 2 	& 3 	& 4\\
     \hline
     $N=1$	     & 	     & 	&  	& 1 	& -2 	& 1 	&  	&   	&  \\
     $N=2$	     &  	    & 	&-1/12	&4/3	&-5/2	&4/3	&-1/12	&   	&  \\
     $N=3$	     & 	     & 1/90	&-3/20	&3/2	&-49/18	&3/2	&-3/20	&1/90	&  \\
     $N=4$	     &-1/560 &8/315	&-1/5	&8/5	&-205/72&8/5	&-1/5	&8/315	&-1/560 \\
     \hline
   \end{tabular}
\end{table*}

Keep in mind that we only need to guarantee the correctness of the wavefield in the original model zone $A_1A_2A_3A_4$. However, the saved wavefield in $A_1A_2A_3A_4\backslash B_1B_2B_3B_4$ is also correct. Is it possible to further shrink it to reduce number of points for saving? The answer is true. Our solution is: saving the inner part neighboring the boundary $A_1A_2A_3A_4\backslash D_1D_2D_3D_4$, as shown in Figure 3b. We call it the effective boundary for regular finite difference scheme.

After $nt$ steps of forward modeling, we begin out backward propagation with the last 2 wavefield snap $p^{nt}$ and $p^{nt-1}$ and saved effective boundaries in $A_1A_2A_3A_4\backslash D_1D_2D_3D_4$. At that moment, the wavefield is correct for every grid point. (Of course, the correctness of the wavefield in $A_1A_2A_3A_4$ is guaranteed.) At time $k$, we assume the wavefield in $A_1A_2A_3A_4$ is correct. One step of backward propagation means $A_1A_2A_3A_4$ is shrunk to $D_1D_2D_3D_4$. In other words, the wavefield in $D_1D_2D_3D_4$ is correctly reconstructed. Then we load the saved effective boundary of time $k$ to overwrite the zone $A_1A_2A_3A_4\backslash D_1D_2D_3D_4$. Again, all the points of the wavefield in $A_1A_2A_3A_4$ are correct. We repeat this overwriting and computing process from one time step to another ($k\rightarrow k-1$), in reverse time order. It is important to note that the wavefield in the boundary $C_1C_2C_3C_4\backslash A_1A_2A_3A_4$ may not be correct because the points here are neither saved nor correctly reconstructed from the previous step.

\plot{fig2}{width=0.8\textwidth}{1-D schematic plot of required points in regular grid for boundary saving. Computing the laplacian needs $N$ points in the extended boundary zone, the rest $N+1$ points in the inner model grid. $N$ points is required for boundary saving.}

\plot{fig3}{width=\textwidth}{A 2-D sketch of required points for boundary saving for regular grid finite difference: (a) The scheme proposed by \cite{dussaud2008computational} (red zone). (b) Proposed effective boundary saving scheme (gray zone).}

\subsection{Effective boundary for staggered grid finite difference}

The limitation of boundary saving strategy proposed in \cite{dussaud2008computational} is that only regular grid finite difference scheme is considered in reverse time migration. In the case of staggered grid, half points are employed to obtain higher accuracy for finite difference. Recursion from time $k$ to $k+1$ (or $k-1$) may not be realized with ease due to the laplacian operator, which involves second derivative. An effective approach is to split equation \eqref{eq:scalar_wav} into several first derivative equations or combinations of first derivative and second derivative equations. The first derivative is defined as
\begin{equation}
\partial_u f=\frac{1}{\Delta u}\left(
\sum_{i=1}^{N} c_i(f[u+i\Delta u/2]-f[u-i\Delta u/2])\right), u=x,z
\end{equation}
where the finite difference coefficients are listed in Table 2, see \ref{appendix:1} for more details.


\begin{table*}
  \centering
  \caption{Finite difference coefficients for staggered grid}\label{table:2}
  \begin{tabular}{l|c|c|c|c}
     \hline
     Order ($2N$) & 1 		& 2 		& 3 		& 4\\
     \hline
     $N=1$	&1 		&  		&  		&   	\\
     $N=2$ 	&1.125		&-0.0416667	&		&   	\\
     $N=3$	&1.171875	&-0.0651041667	&0.0046875	&	\\
     $N=4$	&1.1962890625	&-0.079752604167&0.0095703125	&-0.000697544642857\\
     \hline
   \end{tabular}
\end{table*}

The use of half points in staggered grid makes the effective boundary a little different from that in regular grid. To begin with, I define some intermediate auxiliary variables: $Ax:=\partial_x p$, $Az:=\partial_z p$, $Px:=\partial_x Ax$ and $Pz:=\partial_z Az$. Thus the acoustic wave equation reads
\begin{equation}\label{eq:acoustic1}
\left\{
\begin{split}
&\frac{\partial^2 p}{\partial t^2}=v^2\left(Px+Pz\right)\\
&Px=\partial_x Ax,Pz=\partial_z Ax\\
&Ax=\partial_x p, Az=\partial_z p
\end{split}
\right.
\end{equation}
It means that we have to conduct 2 finite difference steps (one for $Ax$ and $Az$ and the other for $Px$ and $Pz$ ) to compute the laplacian in one step of time marching. Take 8-th order finite difference in $x$ dimension for example. As can be seen from Figure 4, computing $\partial_{xx}$ at $Px_0$ needs the correct values at $Ax_4$,$Ax_3$,$Ax_2$,$Ax_1$ in the boundary; computing $Ax_4$,$Ax_3$,$Ax_2$,$Ax_1$ needs the correct values at $Px_4$,$Px_5$,$Px_6$,$Px_7$ in the boundary. Thus, $2N-1=7$ points in boundary zone is needed to guarantee the correctness of the inner wavefield. Speaking two dimensionally, some points in the four corners at in $B_1B_2B_3B_4$ may be required, as shown in Figure 5a. The reason is that you are working with laplacian, not second derivative in one dimension. Again, we switch our boundary saving part from out of $A_1A_2A_3A_4$ to $A_1A_2A_3A_4\backslash D_1D_2D_3D_4$. The proposed effective boundary for staggered finite difference needs $2N-1$ points to be saved on each side, see Figure 5b.

\plot{fig4}{width=0.8\textwidth}{$2N$-th order staggered grid finite difference: correct backward propagation needs $2N-1$ points on one side. For $N=4$, computing $\partial_{xx}$ at $Px_0$ needs the correct values at $Ax_4$, $Ax_3$, $Ax_2$, $Ax_1$ in the boundary; computing $Ax_4$,$Ax_3$, $Ax_2$, $Ax_1$ needs the correct values at $Px_4$, $Px_5$, $Px_6$, $Px_7$ in the boundary. Thus, $2N-1=7$ points in boundary zone is required to guarantee the correctness of the inner wavefield.
}

\plot{fig5}{width=\textwidth}{A 2-D sketch of required points for boundary saving for staggered grid finite difference: (a) Saving the points outside the model  (red region). (b) Effective boundary, saving the points inside the model zone  (gray region).}

\subsection{Storage analysis}

For the convenience of complexity analysis, we define the size of the original model as $nz\times nx$. In each direction, we pad the model with the $nb$ points on both sides as the boundary. Thus, the extended model size becomes $(nz+2nb)(nx+2nb)$. Conventionally one has to save the whole wavefield within the model size on the disk. The required number of points is
\begin{equation}
 nz\cdot nx
\end{equation}
According to \cite{dussaud2008computational}, for $2N$-th order finite difference in regular grid,  $N$ points on each side are added to guarantee the correctness of inner wavefield. The saving amount of every time step is
\begin{equation}
 2N\cdot nz+2N\cdot nx=2N(nz+nx).
\end{equation}
In the proposed effective boundary saving strategy, the number becomes
\begin{equation}
 2N\cdot nz+2N\cdot nx-4N^2=2N(nz+nx)-4N^2.
\end{equation}

In the case of staggered grid, there are $2N-1$ points on each side. Allowing for the corners, the number for the effective boundary saving is
\begin{equation}
2(2N-1)nz+2(2N-1)nx-4(2N-1)^2=2(2N-1)(nz+nx)-4(2N-1)^2
\end{equation}
Assume the forward modeling is performed $nt$ steps using the floating point format on the computer. The saving amount will be multiplied by $nt\cdot \mathrm{sizeof(float)}=4nt$. Table 3 lists this memory requirement for different boundary saving strategies. \footnote{The four coners are saved twice for the convenience of practical implementation.}


\begin{table*}
  \centering
  \caption{Storage requirement for different saving strategy}\label{table:3}
  \begin{tabular}{l|l}
     \hline
     Boundary saving scheme	  			&  Saving amount (Unit: Bytes)\\
     \hline
     Conventional saving strategy			&  $4 nt\cdot nz\cdot nx$ \\
     Dussaud's: regular grid				&  $4 nt\cdot2N(nz+nx) $ \\
     Effective boundary: regular grid			&  $4 nt\cdot(2N(nz+nx)-4N^2) $	\\
     Effective boundary: staggered grid			&  $4 nt\cdot(2(2N-1)(nz+nx)-4(2N-1)^2) $ \\
     \hline
   \end{tabular}
\end{table*}

It is noteworthy that using boundary saving, the storage requirement can be greatly reduced, compared the conventional method. The proposed effective boundary saving will save $4nt\cdot 4N^2$ Bytes in regular grid finite difference. The storage requirement of staggered grid based effective boundary saving is about $(2N-1)/N$ times of that in the regular grid finite difference, by observing $2N\ll nb\ll nx,nz$ \footnote{To obtain nice absorbing effect, typically the sponge ABC requires the thickness of the boundary to be $nb\approx30$ or more, while PML boundary condition and its variants needs $nb\approx 20\sim 30$. The order of finite difference is always $2N\leq 10$ ($N\leq 5$).}. Generally speaking, the sponge ABC is easier to carry out in both regular and staggered grid, while the PML boundary condition is a little complicated and more suitable for time recursion with staggered grid.


\section{Resort to zero-copy pinned memory}

\subsection{Boundary saving on device: A challenge}

Besides the additional variable allocation, the amount of conventional boundary saving strategy is still a bottleneck to save all boundaries on GPU to avert the CPU saving and data exchange, which will slow down GPU-based RTM. Consider two benchmark models: Marmousi and Sigsbee. The size of Marmousi model is $nz\times nx=751\times 2301$, while the size of Sigsbee model is much larger: $nz\times nx=1201\times3201$. Assume $nt=10000$ and the order of finite difference in RTM is chosen to be  $2N=8$ to obtain high quality image. A storage comparison for the benchmark models using different saving schemes has been made in Table 4.
Conventionally, one have to store 64.4 GB for Marmousi model and 143.2 GB for Sigsbee model on the disk of the computer.
Note that other necessary variable allocation is not included in the calculation above. Obviously, it is prohibitive to store all the wavefield on device for both Marmousi and Sigsbee on a common machine. With the help of \cite{dussaud2008computational} boundary saving or regular grid based effective boundary saving, the storage requirement will be greatly reduced, about 0.9 GB and 1.3 GB for the two models. Staggered grid finite difference is preferable due, however, the saving amount of effective boundary needs 1.6 GB and 2.3 GB for the two models, much larger than regular grid. However, even if you have 2 GB GPU resource on your computer, allowing for other variable allocations on device, it is still impractical to save all the boundaries on GPU for Sigsbee using staggered grid, and let alone our poorer hardware condition (only 1GB GPU resource). In a word, the potential challenge may still lie there depending on your computer hardware.


\begin{table*}
  \centering
  \caption{Storage comparison for benchmark models ($nt=10000$, $2N=8$)}\label{table:4}
  \begin{tabular}{l|c|c}
     \hline
     Boundary saving scheme	  					&  Marmousi (751*2301)	& Sigsbee (1201*2301)\\
     \hline
     Save on the disk of computer					&  64.4  GB		& 143.2 GB\\
     Dussaud's or effective boundary: regular grid 			&  0.9	GB		& 1.3 GB\\
     Effective boundary: staggered grid					&  1.6	GB		& 2.3 GB\\
     \hline
   \end{tabular}
\end{table*}

\subsection{A practical solution: incorporating pinned memory}

Fortunately, page-locked (also known as pinned) host memory provides us a practical solution. Zero-copy system memory has identical coherence and consistency to global memory. Therefore,  copies between page-locked host memory and device memory can be performed concurrently with kernel execution. Pinned memory can be mapped into the address space of the device, eliminating the need to copy it to or from device memory. On systems with a front-side bus, bandwidth between host memory and device memory is higher if host memory is allocated as page-locked and even higher if in addition it is allocated as write-combining memory \citep{nvidia2011nvidia}. Generally, a computer has same or larger amount of resource on host compared with resource on device. Thus, we store a certain  percentage of effective boundary on the page-locked host memory, and the rest on device. A reminder is that the pinned memory is scare resource on the computer and degrade the bandwidth performance if you have to save most of your boundaries with it.



\section{Numerical examples}

\subsection{Exact reconstruction}

The first example is designed to demonstrate the validity of the proposed effective boundary saving strategy. We use a constant velocity model: velocity=2000m/s, $nz=nx=320$, $\Delta z=\Delta x=5m$. The source position is set at the center of the model. We expand the model with PML boundary condition $nb=32$ to obtain nice absorbing effect. The modeling process is performed $nt$ time samples. We record the modeled wavefield snap at $k=420$ and $k=500$, as shown in the top panels of Figure 6. The backward propagation starts from $k=1000$ and ends at $k=1$. In the backward steps, the reconstructed wavefield at $k=500$ and $k=420$ are also recorded, shown in the bottom panels of Figure 6. We also plot the wavefield in the boundary zone in both two panels. Note the correctness of the wavefield in the original model zone is guaranteed while the wavefield in the boundary zone may not be correct.

\plot{fig6}{width=\textwidth}{The wavefield snaps with a constant velocity model: velocity=2000m/s, $nz=nx=320$, $\Delta z=\Delta x=5m$, source at the center. The forward modeling is conducted with $nt=1000$ time samples. (a--b) Modeled wavefield snap at $k=420$ and $k=500$. The backward propagation starts from $k=1000$ and ends at $k=1$. (c--d) Reconstructed wavefield snap at $k=500$ and $k=420$. Note the correctness of the wavefield in the original model zone is guaranteed while the wavefield in the boundary zone may be incorrect.}

\subsection{Marmousi model}
\inputdir{marmousi}

The second example is GPU-based RTM for Marmousi model using our effective boundary saving. The spatial sampling interval is $\Delta x=\Delta z=4m$. 51 shots are deployed. In each shot, 301 receivers are placed in the split shooting mode. The parameters we use are listed as follows: $nt=13000$, $\Delta t=0.3$ ms. Due to the limited resource on our computer, we store 65\% boundaries using page-locked memory. The resulting RTM image after laplacian filtering is shown in Figure 7. As shown in the figure, RTM with the effective boundary saving scheme produces excellent image.

\plot{images}{width=\textwidth}{RTM result of Marmousi model using effective boundary saving scheme (staggered grid finite difference). (a) Result of cross-correlation imaging condition. (b) Result of normalized cross-correlation imaging condition.}

\subsection{Sigsbee model}
\inputdir{sigsbee}

The last example is Sigsbee model. The spatial interval is  $\Delta x=\Delta z=25m$. 55 shots are deployed horizontally. We still perform $nt=13000$ time steps for each shot (301 receivers). Because of the larger model size, 75\% boundaries have to be stored with the aid of pinned memory. Our RTM result is shown in Figure 8. It is interesting to note that the normalized cross-correlation imaging condition greatly improves the deeper parts of the image due to the illumination compensation.

\multiplot{2}{imag1,imag2}{width=0.45\textwidth }{RTM result of Sigsbee model using effective boundary saving scheme (staggered grid finite difference). (a) Result of cross-correlation imaging condition. (b) Result of normalized cross-correlation imaging condition.}

\section{Conclusion}

In this paper, we propose effective boundary saving strategy in GPU-based RTM imaging, for regular grid finite difference and staggered grid finite difference. Even so, the memory requirement of effective boundary saving on GPU is still large for the limited GPU resource. To mitigate this conflict, we use the zero-copy pinned memory on CPU. We demonstrate the proposed approach with numerical examples. Even if the proposed effective boundary saving is still valid without the limitation of GPU or CPU computation, it is very useful for 2-D GPU-based RTM to make all the storage and computation on device. It is straightforward to extend the effective boundary to other orders, 3-D as well as more complex wave equations.


\section{Acknowledgments}

The work of the first author is supported by China Scholarship Council during his visit at The University of Texas at Austin. We wish to thank Sergey Fomel for valuable discussions. The code of even-order GPU-based prestack RTM (combined with convolutional-PML (CPML) boundary condition, order=2, 4, 6, 8, 10) using effective boundary saving strategy is available alongside this paper. The numerical examples are reproducible with the help of Madagascar software package \citep{m8r} (\url{http://www.ahay.org}).

\appendix
\section{Appendix A: Derivation of finite difference coefficients in staggered grid}\label{appendix:1}

The Taylor expansion of the function $f(x+h)$ at $x$ is written as
\begin{equation}\label{eq:Taylor}
f(x+h)=f(x)+\frac{\partial f(x)}{\partial x}h+\frac{1}{2!}\frac{\partial^2 f(x)}{\partial x^2}h^2+\frac{1}{3!}\frac{\partial^3 f(x)}{\partial x^3}h^3+\ldots.
\end{equation}
Similarly, we have
\begin{equation}
f(x-h)=f(x)-\frac{\partial f(x)}{\partial x}h+\frac{1}{2!}\frac{\partial^2 f(x)}{\partial x^2}h^2-\frac{1}{3!}\frac{\partial^3 f(x)}{\partial x^3}h^3+\ldots.
\end{equation}

Staggered grid finite difference expands the 1st-order derivatives with half-integer points:
\begin{equation}
 \begin{split}
\frac{\partial f}{\partial x}=&a_1\frac{f(x+\Delta x/2)-f(x-\Delta x/2)}{\Delta x}\\
&+a_2\frac{f(x+3\Delta x/2)-f(x-3\Delta x/2)}{3\Delta x}\\
&+a_3\frac{f(x+5\Delta x/2)-f(x-5\Delta x/2)}{5\Delta x}+\cdots\\
=&c_1\frac{f(x+\Delta x/2)-f(x-\Delta x/2)}{\Delta x}\\
&+c_2\frac{f(x+3\Delta x/2)-f(x-3\Delta x/2)}{\Delta x}\\
&+c_3\frac{f(x+5\Delta x/2)-f(x-5\Delta x/2)}{\Delta x}+\cdots\\
 \end{split}
\end{equation}
where $c_i=a_i/(2i-1)$. Substituting the $f(x+h)$ and $f(x-h)$ with \eqref{eq:Taylor} for $h=\Delta x/2,3\Delta x/2, \ldots$ results in
\begin{equation}
\begin{split}
\frac{\partial f}{\partial x}=&c_1\left(\Delta x \frac{\partial f}{\partial x}+\frac{1}{3}(\frac{\Delta x}{2})^2\frac{\partial^3 f}{\partial x^3}+\cdots\right)/{\Delta x}\\
&+c_2\left(3\Delta x \frac{\partial f}{\partial x}+\frac{1}{3}(\frac{3\Delta x}{2})^2\frac{\partial^3 f}{\partial x^3}+\cdots\right)/{\Delta x}\\
&+c_3\left(5\Delta x \frac{\partial f}{\partial x}+\frac{1}{3}(\frac{5\Delta x}{2})^2\frac{\partial^3 f}{\partial x^3}+\cdots\right)/{\Delta x}+\ldots\\
=&(c_1+3c_2+5c_3+7c_4+\cdots)\frac{\partial f}{\partial x}\\
&+\frac{\Delta x^2}{3\cdot 2^2}(c_1+3^3c_2+5^3c_3+7^3c_4+\cdots)\frac{\partial^3 f}{\partial x^3}\\
&+\frac{\Delta x^4}{3\cdot 2^4}(c_1+3^5c_2+5^5c_3+7^5c_4+\cdots)\frac{\partial^5 f}{\partial x^5}+\cdots\\
=&(a_1+a_2+a_3+a_4+\cdots)\frac{\partial f}{\partial x}\\
&+\frac{\Delta x^2}{3\cdot 2^2}(a_1+3^2a_2+5^2a_3+7^2a_4+\cdots)\frac{\partial^3 f}{\partial x^3}\\
&+\frac{\Delta x^4}{3\cdot 2^4}(a_1+3^4a_2+5^4a_3+7^4a_4+\cdots)\frac{\partial^5 f}{\partial x^5}+\cdots\\
\end{split}
\end{equation}
Thus, taking first $N$ terms means
\begin{equation}
\left\{
\begin{split}
a_1+a_2+a_3+\cdots+a_N&=1\\
a_1+3^2a_2+5^2a_3+\cdots+(2N-1)^2a_N&=0\\
a_1+3^4a_2+5^4a_3+\cdots+(2N-1)^4a_N&=0\\
\cdots	&\\
a_1+3^{2N-2}a_2+5^{2N-2}a_3+\cdots)+(2N-1)^{2N-2}a_N&=0\\
\end{split}
\right.
\end{equation}
In matrix form,
\begin{gather}
\underbrace{
\begin{bmatrix}
	1 & 1 & \ldots & 1\\
	1^2 & 3^2 & \ldots & (2N-1)^2\\
	\vdots & 	&	\ddots	& \vdots	\\
	1^{2N-2} & 3^{2N-2} & \ldots & (2N-1)^{2N-2}\\
\end{bmatrix}
}_{\textbf{V}^T}
\underbrace{
\begin{bmatrix}
a_1\\
a_2\\
\vdots\\
a_N\\
\end{bmatrix}
}_{\textbf{a}}=
\underbrace{
\begin{bmatrix}
1\\
0\\
\vdots\\
0\\
\end{bmatrix}
}_{\textbf{b}}
\end{gather}
You may think about inversing the matrix to obtain the solution but it is not stable. Fortunately, the above matrix equation is Vandermonde-like system: $\textbf{V}^T\textbf{a}=\textbf{b}$, $\textbf{a}=(a_1, a_2,\ldots, a_N)^T$. The Vandermonde matrix
\begin{equation}
\textbf{V}^T=
\begin{bmatrix}
1 & 1 & \ldots & 1\\
x_1 & x_2 & \ldots & x_{N}\\
\vdots &  & \ddots & \vdots\\
x_1^{N-1} & x_2^{N-1} & \ldots & x_N^{N-1}\\
\end{bmatrix}
\end{equation}
in which $x_i=(2i-1)^2$, has analytic solutions. $\textbf{V}^T\textbf{a}=\textbf{b}$ can be solved using the specific algorithm, see \cite{bjorck1996numerical}. And we obtain
\begin{equation}
\frac{\partial f}{\partial x}=\frac{1}{\Delta x}\sum_{i=1}^N c_i(f(x+i\Delta x/2)-f(x-i\Delta x/2)+O(\Delta x^{2N})
\end{equation}

\appendix
\section{Appendix B: CPML implementation in staggered grid}
To combine the absorbing effects into the acoustic equation, we merely need to combine two convolution terms into the above equations:
\begin{equation}
\left\{
\begin{split}
\frac{\partial^2 p}{\partial t^2}&=v^2\left(Px+Pz\right)\\
Px&=\partial_x Ax+\Psi_x\\
Pz&=\partial_z Az+\Psi_z\\
Ax&=\partial_x p+\Phi_x\\
Az&=\partial_z p+\Phi_z
\end{split}
\right.
\end{equation}
where $\Psi_x$, $\Psi_z$ are the convolution terms of $Ax$ and $Az$; $\Phi_x$, $\Phi_z$ are the convolution terms of $Px$ and $Pz$. These convolution terms can be computed via the following relation:
\begin{equation}
\left\{
\begin{split}
\Psi_x^n=b_x \Psi_x^{n-1}+(b_x-1) \partial_x^{n+1/2}Ax\\
\Psi_z^n=b_z \Psi_z^{n-1}+(b_z-1) \partial_z^{n+1/2}Az\\
\Phi_x^n=b_x \Phi_x^{n-1}+(b_x-1) \partial_x^{n-1/2}p\\
\Phi_z^n=b_z \Phi_z^{n-1}+(b_z-1) \partial_z^{n-1/2}p\\
\end{split}
\right.
\end{equation}
where $b_x=e^{-d(x)\Delta t}$ and $b_z=e^{-d(z)\Delta t}$. In the absorbing layers, the damping parameter $d(x)$ we used is \citep{collino2001application}:
\begin{equation}
 d(x)=d_0(\frac{x}{L})^2, d_0=-\frac{3v}{2L}\ln(R)
\end{equation}
where $ L$ indicates the PML thickness; $x$ represents the distance between current position (in PML) and PML inner boundary. $R$ is always chosen as $10^{-3}\sim 10^{-6}$. More details about the derivation of CPML, the interested readers are referred to \cite{collino2001application} and \cite{komatitsch2007unsplit}.



\bibliographystyle{seg}  % style file is seg.bst
\bibliography{bibliography}


