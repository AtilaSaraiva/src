\chapter{Parallel processing in Madagascar}

Modern computers provide parallel computing facilities in the form of
either multiple processing units on one node or multiple distributed
nodes in a cluster. By taking advantage of parallel architectures,
many computational tasks can be significantly accelerated.

A particularly simple yet practically important case is \emph{data
  parallel} algorithms, where the input data can be split into
parallel chunks, processed in parallel by serial algorithms and then
accumulated back into one data stream. Madagascar provides a number of
convenient tools for running serial code into a data parallel fashion
without the need to resolve to low-level programming.

\section{Posix threads}

\section{OpenMP programming and sfomp}

OpenMP (from \emph{Open Multi-Processing}) is an application
programming interface (API) that simplifies parallel tasks on
shared-memory architectures \cite[]{chandra,chapman}. OpenMP appeared
in 1997 (with specifications for Fortran) and is currently supported
by most modern C/C++ and Fortran compilers. The GCC compiler has been
providing support to OpenMP since version 4.2, which appeared in
2007. Madagascar detects the existence of OpenMP at the installation
configuration stage and uses sets the compiler flags appropriately. [FLAGS]

To use OpenMP in your C or Fortran program, you can use special
compiler directives. For example, the following piece of code from
\texttt{\$RSFSRC/user/psava/fdutil.c} uses the \texttt{pragma omp}
directive to instruct the OpenMP-enabled compiler to execute the loop
in parallel.

\lstset{language=c,numbers=left,numberstyle=\tiny,showstringspaces=false}
\lstinputlisting[firstline=574,lastline=585,frame=single]{\RSF/user/psava/fdutil.c}

To simplify OpenMP-based processing for data-parallel tasks,
Madagascar provides \texttt{sfomp} utility. Suppose, for example, that
the input file \texttt{input.rsf} contains a number of traces, which
we want to process in parallel with a bandpass filter. The serial execution
\begin{verbatim}
< input.rsf sfbandpass fhi=50 > output.rsf
\end{verbatim}
becomes parallel by inserting \texttt{sfomp} before the command, as follows:
\begin{verbatim}
< input.rsf sfomp sfbandpass fhi=50 > output.rsf
\end{verbatim}

By default, \texttt{sfomp} uses the number of threads equivalent to
the number of available cores. To use a different number, you can set
\texttt{OMP\_NUM\_THREADS} environmental variable.

By default, \texttt{sfomp} splits the input over the last dimension,
processes different parts of the data, and concatenates the outputs
along the same dimension. To change this behavior, you can use
\texttt{split=} and \texttt{join=} parameters. For example, to
transpose a 2-D dataset in parallel, we can split it over one
dimension and join over the other dimension:
\begin{verbatim}
< input.rsf sfomp sftransp split=1 join=2 > output.rsf
\end{verbatim}


\section{MPI programming and sfmpi}

MPI (from \emph{Message Passing Interface}) is a popular
system/protocol for parallel application on both shared-memory and
distributed-memory architectures \cite[]{pacheco,gropp}. There are several alternative
implementations of MPI, the popular open-source implementations
include MPICH\footnote{\url{https://www.mpich.org/}} and Open
MPI\footnote{\url{https://www.open-mpi.org/}}. Madagascar detects the
existence of MPI at the installation configuration stage. [FLAGS]

To simplify MPI-based processing for data-parallel tasks,
Madagascar provides \texttt{sfmpi} utility...

\section{GPU programming}

\section{Parallel processing in SCons: pscons}

\section{Parallel processing on shared clusters: sfbatch}

\bibliographystyle{seg}
\bibliography{parallel}

